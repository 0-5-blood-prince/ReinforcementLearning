{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import gym_gridworlds\n",
    "import rlpa2\n",
    "import mygrid\n",
    "import sklearn\n",
    "import numpy as np\n",
    "enva = gym.make(\"gridenv-v0\")\n",
    "envb = gym.make(\"gridenv-v1\")\n",
    "envc = gym.make(\"gridenv-v2\")\n",
    "\n",
    "from collections import defaultdict\n",
    "def sarsal(env,num_episodes,lamb,gamma = 0.9, alpha = 0.15, epsilon = 0.1):\n",
    "    Q = defaultdict(lambda:np.zeros(4))\n",
    "    E = defaultdict(lambda:np.zeros(4))\n",
    "    env.reset()\n",
    "#     env.render()\n",
    "    Episodelen = []\n",
    "    AvgReward = []\n",
    "    for episode in range(num_episodes):\n",
    "#         env.render()\n",
    "        resetedpos = env.reset()\n",
    "#         print(\"Start state\",resetedpos)\n",
    "        state = resetedpos\n",
    "        rew = 0\n",
    "        length = 0\n",
    "        while(1):\n",
    "            length+=1\n",
    "            if(np.count_nonzero(Q[state])==0):\n",
    "                bestaction = random.randint(0,3)\n",
    "            else:\n",
    "                bestaction = np.argmax(Q[state])\n",
    "            prob_ba = 1.0 - epsilon + (epsilon/4)\n",
    "            ba = random.uniform(0,1)\n",
    "            Action_sel = -1\n",
    "            if(ba<=prob_ba):\n",
    "                Action_sel = bestaction\n",
    "            else:\n",
    "                t =random.randint(1,3)\n",
    "                c =1\n",
    "                for a in range(4):\n",
    "                    if(a==bestaction):\n",
    "                        continue\n",
    "                    else:\n",
    "                        if(c==t):\n",
    "                            Action_sel = a\n",
    "                            break\n",
    "                        else:\n",
    "                            c+=1\n",
    "            next_state, reward,isT, _ = env.step(Action_sel)\n",
    "            rew+=reward\n",
    "            if(np.count_nonzero(Q[next_state])==0):\n",
    "                best_n_action = random.randint(0,3)\n",
    "            else:\n",
    "                best_n_action = np.argmax(Q[next_state])\n",
    "            prob_ba = 1.0 - epsilon + (epsilon/4)\n",
    "            ba = random.uniform(0,1)\n",
    "            Action_n_sel = -1\n",
    "            if(ba<=prob_ba):\n",
    "                Action_n_sel = best_n_action\n",
    "            else:\n",
    "                t =random.randint(1,3)\n",
    "                c =1\n",
    "                for a in range(4):\n",
    "                    if(a==best_n_action):\n",
    "                        continue\n",
    "                    else:\n",
    "                        if(c==t):\n",
    "                            Action_n_sel = a\n",
    "                            break\n",
    "                        else:\n",
    "                            c+=1\n",
    "            delta = reward + gamma * Q[next_state][Action_n_sel] - Q[state][Action_sel]\n",
    "            E[state][Action_sel]+=1\n",
    "            \n",
    "            for s,_ in Q.items() :\n",
    "                Q[s][:] += alpha * delta * E[s][:]\n",
    "                E[s][:] = gamma*lamb*E[s][:]\n",
    "            if isT:\n",
    "                break\n",
    "            state = next_state\n",
    "        AvgReward.append(rew)\n",
    "        Episodelen.append(length)\n",
    "    return AvgReward,Episodelen,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BELOW CODE IS TO CHANGE REWARD TO -0.01 to obtain Results FAST USED Only in case of SARSA(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "class GridWorld(object):\n",
    "    def __init__(self,n=12,m=12):\n",
    "        self.grid = np.zeros((m,n))\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.n_actions = 4\n",
    "        self.stateSpace = [i for i in range(self.m*self.n)]\n",
    "        self.startstates = [60,72,120,132]\n",
    "        self.startind = random.randint(0,3)\n",
    "        self.agentposition = self.startstates[self.startind]\n",
    "        ##Terminal state info say A\n",
    "        self.stateSpace.remove(79)#A index\n",
    "        self.stateSpaceplus = [i for i in range(self.m*self.n)]\n",
    "        self.actionSpace = {'U':-self.n,'D':self.n,'L':-1,'R':1}\n",
    "        self.possibleActions = ['U','D','L','R']\n",
    "        #Rewards\n",
    "        self.rewards  = np.zeros((m,n))\n",
    "        \n",
    "        for i in self.stateSpace:\n",
    "            x = i // self.m\n",
    "            y = i%self.n\n",
    "            self.rewards[x][y]=-0.01\n",
    "            if y in range(3,9):\n",
    "                if y == 8:\n",
    "                    if x in range(2,7):\n",
    "                        self.rewards[x][y]-=1\n",
    "                else:\n",
    "                    if x in range(2,9):\n",
    "                        self.rewards[x][y]-=1\n",
    "            if y in range(4,8):\n",
    "                if y == 7:\n",
    "                    if x in range(3,6):\n",
    "                        self.rewards[x][y]-=1\n",
    "                else:\n",
    "                    if x in range(3,8):\n",
    "                        self.rewards[x][y]-=1\n",
    "            if y in range(5,7):\n",
    "                if y == 6:\n",
    "                    if x==4:\n",
    "                        self.rewards[x][y]-=1\n",
    "                else:\n",
    "                    if x in range(4,7):\n",
    "                        self.rewards[x][y]-=1\n",
    "        self.rewards[6][7]=10  #A reward\n",
    "        self.setState(self.agentposition)\n",
    "                    \n",
    "                    \n",
    "        \n",
    "    def isTerminal(self,state):\n",
    "        return state in self.stateSpaceplus and state not in self.stateSpace\n",
    "    def getAgentRnC(self):\n",
    "        x = self.agentposition // self.m\n",
    "        y = self.agentposition % self.n\n",
    "        return x,y\n",
    "    def setState(self,state):\n",
    "        x,y = self.getAgentRnC()\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "        self.grid[x][y]=-1\n",
    "        self.agentposition = state\n",
    "        x,y = self.getAgentRnC()\n",
    "        self.grid[x][y]=1\n",
    "    def offgrid(self,newState,oldState):\n",
    "        if newState not in self.stateSpaceplus:\n",
    "#             print(\"off\")\n",
    "            return True\n",
    "        elif oldState % self.m == 0 and newState % self.m == self.m - 1:\n",
    "            return True\n",
    "        elif oldState % self.m == self.m-1 and newState % self.m == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def step(self,action):\n",
    "        action = self.possibleActions[action]\n",
    "        x,y = self.getAgentRnC()\n",
    "        \n",
    "        prob_w = random.uniform(0,1)\n",
    "        wind = False\n",
    "#         if(prob_w<=0.5):\n",
    "#             wind = True\n",
    "        #stoc = False\n",
    "        prob_s = random.uniform(0,1)\n",
    "        action_m = action\n",
    "        if(prob_s<=0.9):\n",
    "            action_m = action\n",
    "        else:\n",
    "            t = random.randint(1,3)\n",
    "            c = 1\n",
    "            for a in self.actionSpace:\n",
    "                if(a==action):\n",
    "                    continue\n",
    "                else:\n",
    "                    if(c==t):\n",
    "                        action_m = a\n",
    "                        break\n",
    "                    c+=1\n",
    "                \n",
    "        resultingstate = self.agentposition + self.actionSpace[action_m]\n",
    "        trans_state = 0\n",
    "        reward = 0\n",
    "        #here Reward will be after windapplication Think \n",
    "        #Say you got into terminal by moving west and wind blows you east you\n",
    "        #remain in the same position\n",
    "        if not self.offgrid(resultingstate,self.agentposition):\n",
    "            trans_state = resultingstate\n",
    "        else:\n",
    "#             print(\"is off\",resultingstate)\n",
    "            trans_state = self.agentposition\n",
    "#             print(trans_state)\n",
    "#         if(wind):\n",
    "#             result_wind = trans_state + self.actionSpace['R']\n",
    "#             if not self.offgrid(result_wind,trans_state):\n",
    "#                 trans_state = result_wind\n",
    "#             else:\n",
    "# #                 print(\"is off\",result_wind)\n",
    "#                 trans_state = trans_state\n",
    "            \n",
    "#                 print(trans_state)\n",
    "        self.setState(trans_state)\n",
    "        x_end = trans_state // self.m\n",
    "        y_end = trans_state % self.n\n",
    "        isT = self.isTerminal(self.agentposition)\n",
    "#         print(\"state\")\n",
    "#         print(trans_state)\n",
    "#         print(x_end)\n",
    "#         print(y_end)\n",
    "    \n",
    "        return trans_state,self.rewards[x_end][y_end],isT,None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.grid = np.zeros((self.m,self.n))\n",
    "        self.startind = random.randint(0,3)\n",
    "        self.agentposition = self.startstates[self.startind]\n",
    "        return self.agentposition\n",
    "    def render(self):\n",
    "        print('-----------------')\n",
    "        for row in self.grid:\n",
    "            for col in row:\n",
    "                if col==0:\n",
    "                    print('-',end =\" \")\n",
    "                elif col==1 or col==-1:\n",
    "                    print('X',end =\" \")\n",
    "            print('\\n')\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en=GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Max is  9117\n",
      "1\n",
      "Max is  4505\n",
      "2\n",
      "Max is  4032\n",
      "3\n",
      "Max is  1469\n",
      "4\n",
      "Max is  10774\n",
      "5\n",
      "Max is  17498\n",
      "6\n",
      "Max is  10862\n",
      "7\n",
      "Max is  11920\n",
      "8\n",
      "Max is  11439\n",
      "9\n",
      "Max is  3374\n",
      "10\n",
      "Max is  2918\n",
      "11\n",
      "Max is  16280\n",
      "12\n",
      "Max is  4802\n",
      "13\n",
      "Max is  1686\n",
      "14\n",
      "Max is  6378\n",
      "15\n",
      "Max is  2041\n",
      "16\n",
      "Max is  19734\n",
      "17\n",
      "Max is  8999\n",
      "18\n",
      "Max is  8008\n",
      "19\n",
      "Max is  41117\n",
      "20\n",
      "Max is  13228\n",
      "21\n",
      "Max is  11820\n",
      "22\n",
      "Max is  12181\n",
      "23\n",
      "Max is  2291\n",
      "24\n",
      "Max is  8581\n",
      "25\n",
      "Max is  3511\n",
      "26\n",
      "Max is  5491\n",
      "27\n",
      "Max is  2860\n",
      "28\n",
      "Max is  13006\n",
      "29\n",
      "Max is  9254\n",
      "30\n",
      "Max is  7925\n",
      "31\n",
      "Max is  6743\n",
      "32\n",
      "Max is  19458\n",
      "33\n",
      "Max is  13200\n",
      "34\n",
      "Max is  8762\n",
      "35\n",
      "Max is  8841\n",
      "36\n",
      "Max is  17648\n",
      "37\n",
      "Max is  12185\n",
      "38\n",
      "Max is  19389\n",
      "39\n",
      "Max is  13336\n",
      "40\n",
      "Max is  10519\n",
      "41\n",
      "Max is  7166\n",
      "42\n",
      "Max is  3163\n",
      "43\n",
      "Max is  3805\n",
      "44\n",
      "Max is  2599\n",
      "45\n",
      "Max is  1661\n",
      "46\n",
      "Max is  3678\n",
      "47\n",
      "Max is  12209\n",
      "48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-78eca21807fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msarsal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_episode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max is \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-efeacf279e67>\u001b[0m in \u001b[0;36msarsal\u001b[0;34m(env, num_episodes, lamb, gamma, alpha, epsilon)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episode = 500\n",
    "Q_sarsa = defaultdict(lambda:np.zeros(4))\n",
    "r_sarsa = np.zeros(num_episode)\n",
    "l_sarsa = np.zeros(num_episode)\n",
    "\n",
    "num_runs = 50\n",
    "smooth = 5\n",
    "for i in range(num_runs):\n",
    "    print(i)\n",
    "    \n",
    "    r,l,q = sarsal(en,num_episode,1.0)\n",
    "    print(\"Max is \",np.max(l))\n",
    "    for j in range(num_episode):\n",
    "        r_sarsa[j]=(r_sarsa[j]*(i)+r[j])/(i+1)\n",
    "        l_sarsa[j]=(l_sarsa[j]*(i)+l[j])/(i+1)\n",
    "    for k in range(144):\n",
    "        for a in range(4):\n",
    "            Q_sarsa[k][a]=(Q_sarsa[k][a]*(i)+q[k][a])/(i+1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = []\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# num_episode=100\n",
    "for i in range(num_episode):\n",
    "    T.append(i+1)\n",
    "plt.title(\"Sarsa(1)Average reward of Episode for 50 runs C\")\n",
    "plt.xlabel(\"Num episodes\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.plot(T,r_sarsa)\n",
    "plt.show()\n",
    "plt.title(\"Sarsa(1)Average length of Episode for 50 runs C\")\n",
    "plt.xlabel(\"Num episodes\")\n",
    "plt.ylim(0,2000)\n",
    "plt.ylabel(\"Length of Episode\")\n",
    "plt.plot(T,l_sarsa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
